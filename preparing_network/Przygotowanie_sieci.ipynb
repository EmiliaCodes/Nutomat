{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Emilia Stefanowska, listopad 2022**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generowanie dyktand melodycznych - silnik aplikacji\n",
    "*Generating melodic dictations - application engine*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "from music21 import converter, chord, note, key, interval, pitch\n",
    "import numpy as np\n",
    "from keras.utils import np_utils\n",
    "from keras.layers import LSTM, Input, Dropout, Dense, Embedding, Concatenate\n",
    "from keras.models import Model\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.utils import plot_model\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ustawianie parametrów i folderu z zapisem danych** <br>\n",
    "*Setting the parameters and backup folders*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 training set files in total\n"
     ]
    }
   ],
   "source": [
    "date = str(datetime.now().strftime(\"%m-%d-%Y_%H-%M\"))\n",
    "training_id = '3-4_{}'.format(date) # 3-4 is time signature, and then time of training the network\n",
    "\n",
    "# source_folder = 'training_set/midi/'\n",
    "source_folder = 'MIDI_3-4/'\n",
    "# source_folder = 'Sorted_BACH/3-4/'\n",
    "backup_folder = 'backup/{}/'.format(training_id)\n",
    "\n",
    "files = os.listdir(source_folder)\n",
    "\n",
    "# Creating backup folder if doesn't already exist\n",
    "if not os.path.exists('backup'):\n",
    "    os.mkdir('backup')\n",
    "\n",
    "# Creating backup folder for this specific training session\n",
    "if not os.path.exists(backup_folder):\n",
    "    os.mkdir(backup_folder)\n",
    "    os.mkdir(os.path.join(backup_folder, 'training_set_backup'))\n",
    "    os.mkdir(os.path.join(backup_folder, 'model'))\n",
    "    \n",
    "backup_training_set_folder = os.path.join(backup_folder, 'training_set_backup')\n",
    "model_folder = os.path.join(backup_folder, 'model')\n",
    "\n",
    "print('%s training set files in total' % len(files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Model parameters\n",
    "state = 'read_and_save' # 'load'\n",
    "seq_len = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pitch_read = [] # training set pitch matrix\n",
    "rhythm_read = [] # training set rhythm matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Odczytywanie i zapisywanie informacji ze zbioru treningowego** <br>\n",
    "*Reading and saving data from the training set*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you want to read new pieces in the training set\n",
    "if state == 'read_and_save':\n",
    "    for file in files:\n",
    "        dictation = converter.parse(source_folder + file)\n",
    "        \n",
    "        # Transpose to C-major\n",
    "        dictation_key_signature = dictation.analyze('key')\n",
    "        if (dictation_key_signature != key.Key('C')):\n",
    "            i = interval.Interval(dictation_key_signature.tonic, pitch.Pitch('C'))\n",
    "            dictation = dictation.transpose(i).transpose('P8')\n",
    "            \n",
    "        # Adding starting symbols to mark beginning of the piece\n",
    "        pitch_read.extend(['S'] * seq_len)\n",
    "        rhythm_read.extend([0.0] * seq_len)\n",
    "        \n",
    "        part_stream = dictation.parts.stream()\n",
    "        my_part = part_stream[0] # ensuring we will use only the top melody \n",
    "        \n",
    "        for element in my_part.flat.notesAndRests:         \n",
    "            if element.isNote:\n",
    "                pitch_read.append(str(element.nameWithOctave))\n",
    "                rhythm_read.append(element.duration.quarterLength)\n",
    "\n",
    "            if element.isRest:\n",
    "                pitch_read.append(str(element.name))  # 'rest'\n",
    "                rhythm_read.append(element.duration.quarterLength)\n",
    "                \n",
    "            if isinstance(element, chord.Chord): # if chord insert only the highest note\n",
    "                pitch_read.append(element.pitches[-1].nameWithOctave)\n",
    "                rhythm_read.append(element.duration.quarterLength)\n",
    "\n",
    "    # Saving training set pitch and rhyhtm matrices into binary files\n",
    "    with open(os.path.join(backup_training_set_folder, 'pitch'), 'wb') as file:\n",
    "        pickle.dump(pitch_read, file)\n",
    "    with open(os.path.join(backup_training_set_folder, 'rhythm'), 'wb') as file:\n",
    "        pickle.dump(rhythm_read, file)\n",
    "    \n",
    "    # Create dictionaries with unique pitch and rhythm values and saving into binary files\n",
    "    pitch_sorted = sorted(set(pitch_read))\n",
    "    pitch_dict = dict((number, pitch) for pitch, number in enumerate(pitch_sorted))\n",
    "    pitch_dict_reveresed = dict((pitch, number) for pitch, number in enumerate(pitch_sorted))\n",
    "    \n",
    "    rhythm_sorted = sorted(set(rhythm_read))\n",
    "    rhythm_dict = dict((number, rhythm) for rhythm, number in enumerate(rhythm_sorted))\n",
    "    rhythm_dict_reveresed = dict((rhythm, number) for rhythm, number in enumerate(rhythm_sorted))\n",
    "    dict_tables = [pitch_sorted, pitch_dict, rhythm_sorted, rhythm_dict, pitch_dict_reveresed, rhythm_dict_reveresed]\n",
    "    \n",
    "    with open(os.path.join(backup_training_set_folder, 'dictionaries'), 'wb') as file:\n",
    "        pickle.dump(dict_tables, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ładowanie wcześniej zapisanych danych** <br>\n",
    "*Loading previously saved data*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if state == 'load':\n",
    "    with open(os.path.join(backup_training_set_folder, 'pitch'), 'rb') as file:\n",
    "        pitch_read = pickle.load(file)\n",
    "    with open(os.path.join(backup_training_set_folder, 'rhythm'), 'rb') as file:\n",
    "        rhythm_read = pickle.load(file)\n",
    "    with open(os.path.join(backup_training_set_folder, 'dictionaries'), 'rb') as file:\n",
    "        dict_tables = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Przygotowywanie danych do sieci neuronowej** <br>\n",
    "*Preparing data for neural network*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# We need to prepare data in pitch and rhythm matrices \n",
    "# that contain notes sequences of seq_len number of notes\n",
    "\n",
    "pitch_input = []\n",
    "pitch_output = []\n",
    "rhythm_input = []\n",
    "rhythm_output = []\n",
    "\n",
    "for i in range(len(pitch_read) - seq_len):\n",
    "    pitch_seq_in = pitch_read[i : i + seq_len] # seq_len number of pitches\n",
    "    pitch_seq_out = pitch_read[i + seq_len] # the next note after the sequence of pitch_seq_in   \n",
    "    rhythm_seq_in = rhythm_read[i : i + seq_len] # seq_len number of rhythms\n",
    "    rhythm_seq_out = rhythm_read[i + seq_len] # the next note after the sequence of rhythm_seq_in\n",
    "    \n",
    "    # translating into dictionaries \n",
    "    pitch_input.append([pitch_dict[pitch_name] for pitch_name in pitch_seq_in])\n",
    "    pitch_output.append(pitch_dict[pitch_seq_out])   \n",
    "    rhythm_input.append([rhythm_dict[rhythm_name] for rhythm_name in rhythm_seq_in])\n",
    "    rhythm_output.append(rhythm_dict[rhythm_seq_out])\n",
    "\n",
    "number_of_sequences = len(pitch_input) # useful in reshaping matrices\n",
    "\n",
    "# training input of the network\n",
    "pitch_input = np.reshape(pitch_input, (number_of_sequences, seq_len))\n",
    "rhythm_input = np.reshape(rhythm_input, (number_of_sequences, seq_len))\n",
    "network_in = [pitch_input, rhythm_input] \n",
    "\n",
    "# training output of the network\n",
    "pitch_output = np_utils.to_categorical(pitch_output, num_classes=len(pitch_dict)) # one-hot encoding *kodowanie 1 z n*\n",
    "rhythm_output = np_utils.to_categorical(rhythm_output, num_classes=len(rhythm_dict)) # one-hot encoding *kodowanie 1 z n*\n",
    "network_out = [pitch_output, rhythm_output] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Budowanie modelu sieci neuronowej** <br>\n",
    "*Building the neural network*\n",
    "\n",
    "//Buduję architekturę modelu za pomocą funkcjonalnego API Keras - przydaje się w mechaniźmie uwagi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1115 14:22:19.375891 21384 deprecation_wrapper.py:119] From C:\\Users\\stefa\\.conda\\envs\\generative\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W1115 14:22:19.388357 21384 deprecation_wrapper.py:119] From C:\\Users\\stefa\\.conda\\envs\\generative\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W1115 14:22:19.392981 21384 deprecation_wrapper.py:119] From C:\\Users\\stefa\\.conda\\envs\\generative\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W1115 14:22:19.691483 21384 deprecation_wrapper.py:119] From C:\\Users\\stefa\\.conda\\envs\\generative\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "W1115 14:22:19.696749 21384 deprecation.py:506] From C:\\Users\\stefa\\.conda\\envs\\generative\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W1115 14:22:19.956504 21384 deprecation_wrapper.py:119] From C:\\Users\\stefa\\.conda\\envs\\generative\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W1115 14:22:19.963603 21384 deprecation_wrapper.py:119] From C:\\Users\\stefa\\.conda\\envs\\generative\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Network hyperparameters\n",
    "embedding_size = 120 # 100\n",
    "rnn_units = 300 # 256\n",
    "\n",
    "# Useful training set variables\n",
    "rhythm_size = len(rhythm_dict)\n",
    "pitch_size = len(pitch_dict)\n",
    "\n",
    "# Building the architecture\n",
    "pitch_in = Input(shape = (None,))\n",
    "rhythm_in = Input(shape = (None,))\n",
    "\n",
    "x1 = Embedding(pitch_size, embedding_size)(pitch_in)\n",
    "x2 = Embedding(rhythm_size, embedding_size)(rhythm_in) \n",
    "\n",
    "x = Concatenate()([x1,x2])\n",
    "\n",
    "x = LSTM(rnn_units, return_sequences=True)(x) # First LSTM layer\n",
    "x = Dropout(0.25)(x) \n",
    "\n",
    "x = LSTM(rnn_units)(x) # Second LSTM layer\n",
    "x = Dropout(0.25)(x)\n",
    "                                    \n",
    "pitch_out = Dense(pitch_size, activation = 'softmax', name = 'pitch_output')(x)\n",
    "rhythm_out = Dense(rhythm_size, activation = 'softmax', name = 'rhythm_output')(x)\n",
    "   \n",
    "model = Model([pitch_in, rhythm_in], [pitch_out, rhythm_out])\n",
    "\n",
    "opti = RMSprop(lr = 0.001)\n",
    "model.compile(loss=['categorical_crossentropy', 'categorical_crossentropy'], optimizer=opti)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Zapisywanie schematu modelu i pokazanie podsumowania** <br>\n",
    "*Save the plotted model and show summary*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 120)    4560        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, None, 120)    1080        input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, None, 240)    0           embedding_1[0][0]                \n",
      "                                                                 embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, None, 300)    649200      concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, None, 300)    0           lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   (None, 300)          721200      dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 300)          0           lstm_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "pitch_output (Dense)            (None, 38)           11438       dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "rhythm_output (Dense)           (None, 9)            2709        dropout_2[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 1,390,187\n",
      "Trainable params: 1,390,187\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "plot_model(model, to_file=os.path.join(model_folder, 'model.png'), show_shapes = True, show_layer_names = True)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Stworzenie mechanizmu zapisywania poprawienia wag i trenowanie modelu** <br>\n",
    "*Create weights saving mechanism and train the model*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1115 14:22:20.673196 21384 deprecation.py:323] From C:\\Users\\stefa\\.conda\\envs\\generative\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3083 samples, validate on 771 samples\n",
      "Epoch 1/2000\n",
      "3083/3083 [==============================] - 11s 3ms/step - loss: 3.8955 - pitch_output_loss: 2.5630 - rhythm_output_loss: 1.3325 - val_loss: 3.5816 - val_pitch_output_loss: 2.5180 - val_rhythm_output_loss: 1.0636\n",
      "Epoch 2/2000\n",
      "3083/3083 [==============================] - 9s 3ms/step - loss: 3.3024 - pitch_output_loss: 2.2396 - rhythm_output_loss: 1.0628 - val_loss: 3.2952 - val_pitch_output_loss: 2.3857 - val_rhythm_output_loss: 0.9094\n",
      "Epoch 3/2000\n",
      "3083/3083 [==============================] - 10s 3ms/step - loss: 2.9983 - pitch_output_loss: 2.0726 - rhythm_output_loss: 0.9256 - val_loss: 3.0728 - val_pitch_output_loss: 2.2714 - val_rhythm_output_loss: 0.8015\n",
      "Epoch 4/2000\n",
      "3083/3083 [==============================] - 12s 4ms/step - loss: 2.7982 - pitch_output_loss: 1.9640 - rhythm_output_loss: 0.8342 - val_loss: 3.0738 - val_pitch_output_loss: 2.2715 - val_rhythm_output_loss: 0.8024\n",
      "Epoch 5/2000\n",
      "3083/3083 [==============================] - 12s 4ms/step - loss: 2.6683 - pitch_output_loss: 1.8892 - rhythm_output_loss: 0.7791 - val_loss: 3.1139 - val_pitch_output_loss: 2.2816 - val_rhythm_output_loss: 0.8324\n",
      "Epoch 6/2000\n",
      "3083/3083 [==============================] - 11s 4ms/step - loss: 2.5473 - pitch_output_loss: 1.8235 - rhythm_output_loss: 0.7238 - val_loss: 3.0383 - val_pitch_output_loss: 2.2357 - val_rhythm_output_loss: 0.8025\n",
      "Epoch 7/2000\n",
      "3083/3083 [==============================] - 11s 4ms/step - loss: 2.4184 - pitch_output_loss: 1.7387 - rhythm_output_loss: 0.6797 - val_loss: 3.0576 - val_pitch_output_loss: 2.2729 - val_rhythm_output_loss: 0.7848\n",
      "Epoch 8/2000\n",
      "3083/3083 [==============================] - 12s 4ms/step - loss: 2.3070 - pitch_output_loss: 1.6582 - rhythm_output_loss: 0.6488 - val_loss: 3.0803 - val_pitch_output_loss: 2.2684 - val_rhythm_output_loss: 0.8119\n",
      "Epoch 9/2000\n",
      "3083/3083 [==============================] - 12s 4ms/step - loss: 2.1623 - pitch_output_loss: 1.5703 - rhythm_output_loss: 0.5921 - val_loss: 3.0940 - val_pitch_output_loss: 2.2541 - val_rhythm_output_loss: 0.8399\n",
      "Epoch 10/2000\n",
      "3083/3083 [==============================] - 12s 4ms/step - loss: 2.0066 - pitch_output_loss: 1.4667 - rhythm_output_loss: 0.5399 - val_loss: 3.1599 - val_pitch_output_loss: 2.3078 - val_rhythm_output_loss: 0.8521\n",
      "Epoch 11/2000\n",
      "3083/3083 [==============================] - 13s 4ms/step - loss: 1.8447 - pitch_output_loss: 1.3605 - rhythm_output_loss: 0.4842 - val_loss: 3.2174 - val_pitch_output_loss: 2.3555 - val_rhythm_output_loss: 0.8619\n",
      "Epoch 12/2000\n",
      "3083/3083 [==============================] - 13s 4ms/step - loss: 1.6532 - pitch_output_loss: 1.2359 - rhythm_output_loss: 0.4173 - val_loss: 3.3623 - val_pitch_output_loss: 2.4435 - val_rhythm_output_loss: 0.9188\n",
      "Epoch 13/2000\n",
      "3083/3083 [==============================] - 14s 4ms/step - loss: 1.4991 - pitch_output_loss: 1.1204 - rhythm_output_loss: 0.3787 - val_loss: 3.4982 - val_pitch_output_loss: 2.5087 - val_rhythm_output_loss: 0.9896\n",
      "Epoch 14/2000\n",
      "3083/3083 [==============================] - 13s 4ms/step - loss: 1.3297 - pitch_output_loss: 0.9994 - rhythm_output_loss: 0.3304 - val_loss: 3.5773 - val_pitch_output_loss: 2.5518 - val_rhythm_output_loss: 1.0255\n",
      "Epoch 15/2000\n",
      "3083/3083 [==============================] - 13s 4ms/step - loss: 1.1546 - pitch_output_loss: 0.8796 - rhythm_output_loss: 0.2750 - val_loss: 3.7042 - val_pitch_output_loss: 2.6658 - val_rhythm_output_loss: 1.0384\n",
      "Epoch 16/2000\n",
      "3083/3083 [==============================] - 14s 4ms/step - loss: 1.0182 - pitch_output_loss: 0.7737 - rhythm_output_loss: 0.2445 - val_loss: 3.7891 - val_pitch_output_loss: 2.7111 - val_rhythm_output_loss: 1.0780\n",
      "Epoch 17/2000\n",
      "3083/3083 [==============================] - 12s 4ms/step - loss: 0.8721 - pitch_output_loss: 0.6596 - rhythm_output_loss: 0.2125 - val_loss: 4.0207 - val_pitch_output_loss: 2.8142 - val_rhythm_output_loss: 1.2066\n",
      "Epoch 18/2000\n",
      "3083/3083 [==============================] - 14s 5ms/step - loss: 0.7477 - pitch_output_loss: 0.5701 - rhythm_output_loss: 0.1776 - val_loss: 4.0319 - val_pitch_output_loss: 2.8520 - val_rhythm_output_loss: 1.1800\n",
      "Epoch 19/2000\n",
      "3083/3083 [==============================] - 13s 4ms/step - loss: 0.6282 - pitch_output_loss: 0.4684 - rhythm_output_loss: 0.1598 - val_loss: 4.2074 - val_pitch_output_loss: 2.9306 - val_rhythm_output_loss: 1.2768\n",
      "Epoch 20/2000\n",
      "3083/3083 [==============================] - 14s 5ms/step - loss: 0.5597 - pitch_output_loss: 0.4141 - rhythm_output_loss: 0.1457 - val_loss: 4.4081 - val_pitch_output_loss: 3.0554 - val_rhythm_output_loss: 1.3527\n",
      "Epoch 21/2000\n",
      "3083/3083 [==============================] - 12s 4ms/step - loss: 0.4784 - pitch_output_loss: 0.3601 - rhythm_output_loss: 0.1184 - val_loss: 4.4794 - val_pitch_output_loss: 3.0839 - val_rhythm_output_loss: 1.3955\n",
      "Epoch 22/2000\n",
      "3083/3083 [==============================] - 13s 4ms/step - loss: 0.4162 - pitch_output_loss: 0.3017 - rhythm_output_loss: 0.1145 - val_loss: 4.5521 - val_pitch_output_loss: 3.1802 - val_rhythm_output_loss: 1.3719\n",
      "Epoch 23/2000\n",
      "3083/3083 [==============================] - 12s 4ms/step - loss: 0.3617 - pitch_output_loss: 0.2620 - rhythm_output_loss: 0.0997 - val_loss: 4.7370 - val_pitch_output_loss: 3.2814 - val_rhythm_output_loss: 1.4557\n",
      "Epoch 24/2000\n",
      "3083/3083 [==============================] - 13s 4ms/step - loss: 0.3360 - pitch_output_loss: 0.2435 - rhythm_output_loss: 0.0926 - val_loss: 4.9705 - val_pitch_output_loss: 3.4833 - val_rhythm_output_loss: 1.4872\n",
      "Epoch 25/2000\n",
      "3083/3083 [==============================] - 13s 4ms/step - loss: 0.2954 - pitch_output_loss: 0.2106 - rhythm_output_loss: 0.0848 - val_loss: 5.0187 - val_pitch_output_loss: 3.4759 - val_rhythm_output_loss: 1.5428\n",
      "Epoch 26/2000\n",
      "3083/3083 [==============================] - 16s 5ms/step - loss: 0.2724 - pitch_output_loss: 0.1902 - rhythm_output_loss: 0.0822 - val_loss: 5.1277 - val_pitch_output_loss: 3.5819 - val_rhythm_output_loss: 1.5458\n",
      "Epoch 27/2000\n",
      "3083/3083 [==============================] - 16s 5ms/step - loss: 0.2502 - pitch_output_loss: 0.1669 - rhythm_output_loss: 0.0833 - val_loss: 5.2861 - val_pitch_output_loss: 3.6635 - val_rhythm_output_loss: 1.6226\n",
      "Epoch 28/2000\n",
      "3083/3083 [==============================] - 15s 5ms/step - loss: 0.2238 - pitch_output_loss: 0.1525 - rhythm_output_loss: 0.0713 - val_loss: 5.4186 - val_pitch_output_loss: 3.7944 - val_rhythm_output_loss: 1.6243\n",
      "Epoch 29/2000\n",
      "3083/3083 [==============================] - 15s 5ms/step - loss: 0.2158 - pitch_output_loss: 0.1424 - rhythm_output_loss: 0.0734 - val_loss: 5.2483 - val_pitch_output_loss: 3.6501 - val_rhythm_output_loss: 1.5982\n",
      "Epoch 30/2000\n",
      "3083/3083 [==============================] - 15s 5ms/step - loss: 0.2087 - pitch_output_loss: 0.1306 - rhythm_output_loss: 0.0781 - val_loss: 5.5144 - val_pitch_output_loss: 3.8317 - val_rhythm_output_loss: 1.6827\n",
      "Epoch 31/2000\n",
      "3083/3083 [==============================] - 14s 4ms/step - loss: 0.2010 - pitch_output_loss: 0.1403 - rhythm_output_loss: 0.0607 - val_loss: 5.5437 - val_pitch_output_loss: 3.8586 - val_rhythm_output_loss: 1.6851\n",
      "Epoch 32/2000\n",
      "3083/3083 [==============================] - 13s 4ms/step - loss: 0.1924 - pitch_output_loss: 0.1305 - rhythm_output_loss: 0.0619 - val_loss: 5.6625 - val_pitch_output_loss: 3.9166 - val_rhythm_output_loss: 1.7459\n",
      "Epoch 33/2000\n",
      "3083/3083 [==============================] - 13s 4ms/step - loss: 0.1771 - pitch_output_loss: 0.1200 - rhythm_output_loss: 0.0571 - val_loss: 5.7117 - val_pitch_output_loss: 3.9417 - val_rhythm_output_loss: 1.7700\n",
      "Epoch 34/2000\n",
      "3083/3083 [==============================] - 13s 4ms/step - loss: 0.1620 - pitch_output_loss: 0.1103 - rhythm_output_loss: 0.0517 - val_loss: 5.7389 - val_pitch_output_loss: 3.9681 - val_rhythm_output_loss: 1.7708\n",
      "Epoch 35/2000\n",
      "3083/3083 [==============================] - 12s 4ms/step - loss: 0.1722 - pitch_output_loss: 0.1105 - rhythm_output_loss: 0.0617 - val_loss: 5.9189 - val_pitch_output_loss: 4.0435 - val_rhythm_output_loss: 1.8753\n",
      "Epoch 36/2000\n",
      "3083/3083 [==============================] - 14s 4ms/step - loss: 0.1469 - pitch_output_loss: 0.0973 - rhythm_output_loss: 0.0496 - val_loss: 5.8607 - val_pitch_output_loss: 4.0248 - val_rhythm_output_loss: 1.8359\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/2000\n",
      "3083/3083 [==============================] - 13s 4ms/step - loss: 0.1396 - pitch_output_loss: 0.0960 - rhythm_output_loss: 0.0436 - val_loss: 5.9651 - val_pitch_output_loss: 4.0744 - val_rhythm_output_loss: 1.8906\n",
      "Epoch 38/2000\n",
      "3083/3083 [==============================] - 15s 5ms/step - loss: 0.1587 - pitch_output_loss: 0.1000 - rhythm_output_loss: 0.0587 - val_loss: 6.0081 - val_pitch_output_loss: 4.1310 - val_rhythm_output_loss: 1.8771\n",
      "Epoch 39/2000\n",
      "3083/3083 [==============================] - 13s 4ms/step - loss: 0.1593 - pitch_output_loss: 0.1028 - rhythm_output_loss: 0.0565 - val_loss: 6.0577 - val_pitch_output_loss: 4.1945 - val_rhythm_output_loss: 1.8631\n",
      "Epoch 40/2000\n",
      "3083/3083 [==============================] - 13s 4ms/step - loss: 0.1504 - pitch_output_loss: 0.0979 - rhythm_output_loss: 0.0524 - val_loss: 6.1803 - val_pitch_output_loss: 4.2730 - val_rhythm_output_loss: 1.9073\n",
      "Epoch 41/2000\n",
      "3083/3083 [==============================] - 13s 4ms/step - loss: 0.1339 - pitch_output_loss: 0.0875 - rhythm_output_loss: 0.0464 - val_loss: 6.0729 - val_pitch_output_loss: 4.1731 - val_rhythm_output_loss: 1.8999\n",
      "Epoch 42/2000\n",
      "3083/3083 [==============================] - 12s 4ms/step - loss: 0.1376 - pitch_output_loss: 0.0886 - rhythm_output_loss: 0.0490 - val_loss: 6.2122 - val_pitch_output_loss: 4.2776 - val_rhythm_output_loss: 1.9346\n",
      "Epoch 43/2000\n",
      "3083/3083 [==============================] - 12s 4ms/step - loss: 0.1402 - pitch_output_loss: 0.0898 - rhythm_output_loss: 0.0505 - val_loss: 6.4088 - val_pitch_output_loss: 4.4903 - val_rhythm_output_loss: 1.9185\n",
      "Epoch 44/2000\n",
      "3083/3083 [==============================] - 12s 4ms/step - loss: 0.1349 - pitch_output_loss: 0.0880 - rhythm_output_loss: 0.0469 - val_loss: 6.4178 - val_pitch_output_loss: 4.4157 - val_rhythm_output_loss: 2.0021\n",
      "Epoch 45/2000\n",
      "3083/3083 [==============================] - 13s 4ms/step - loss: 0.1316 - pitch_output_loss: 0.0853 - rhythm_output_loss: 0.0463 - val_loss: 6.4788 - val_pitch_output_loss: 4.4133 - val_rhythm_output_loss: 2.0655\n",
      "Epoch 46/2000\n",
      "3083/3083 [==============================] - 13s 4ms/step - loss: 0.1270 - pitch_output_loss: 0.0844 - rhythm_output_loss: 0.0426 - val_loss: 6.4018 - val_pitch_output_loss: 4.4498 - val_rhythm_output_loss: 1.9521\n",
      "Epoch 47/2000\n",
      "3083/3083 [==============================] - 13s 4ms/step - loss: 0.1228 - pitch_output_loss: 0.0804 - rhythm_output_loss: 0.0424 - val_loss: 6.4890 - val_pitch_output_loss: 4.4836 - val_rhythm_output_loss: 2.0053\n",
      "Epoch 48/2000\n",
      "3083/3083 [==============================] - 12s 4ms/step - loss: 0.1297 - pitch_output_loss: 0.0848 - rhythm_output_loss: 0.0449 - val_loss: 6.7006 - val_pitch_output_loss: 4.6470 - val_rhythm_output_loss: 2.0535\n",
      "Epoch 49/2000\n",
      "3083/3083 [==============================] - 13s 4ms/step - loss: 0.1370 - pitch_output_loss: 0.0902 - rhythm_output_loss: 0.0468 - val_loss: 6.5461 - val_pitch_output_loss: 4.5390 - val_rhythm_output_loss: 2.0072\n",
      "Epoch 50/2000\n",
      "3083/3083 [==============================] - 14s 4ms/step - loss: 0.1291 - pitch_output_loss: 0.0832 - rhythm_output_loss: 0.0459 - val_loss: 6.8055 - val_pitch_output_loss: 4.7123 - val_rhythm_output_loss: 2.0932\n",
      "Epoch 51/2000\n",
      "3083/3083 [==============================] - 12s 4ms/step - loss: 0.1189 - pitch_output_loss: 0.0769 - rhythm_output_loss: 0.0421 - val_loss: 6.7999 - val_pitch_output_loss: 4.6855 - val_rhythm_output_loss: 2.1144\n",
      "Epoch 52/2000\n",
      "3083/3083 [==============================] - 12s 4ms/step - loss: 0.1172 - pitch_output_loss: 0.0731 - rhythm_output_loss: 0.0441 - val_loss: 6.8044 - val_pitch_output_loss: 4.7247 - val_rhythm_output_loss: 2.0798\n",
      "Epoch 53/2000\n",
      "3083/3083 [==============================] - 12s 4ms/step - loss: 0.1248 - pitch_output_loss: 0.0788 - rhythm_output_loss: 0.0459 - val_loss: 6.8630 - val_pitch_output_loss: 4.8077 - val_rhythm_output_loss: 2.0552\n",
      "Epoch 54/2000\n",
      "3083/3083 [==============================] - 15s 5ms/step - loss: 0.1205 - pitch_output_loss: 0.0748 - rhythm_output_loss: 0.0457 - val_loss: 6.8605 - val_pitch_output_loss: 4.8584 - val_rhythm_output_loss: 2.0021\n",
      "Epoch 55/2000\n",
      "3083/3083 [==============================] - 13s 4ms/step - loss: 0.1251 - pitch_output_loss: 0.0871 - rhythm_output_loss: 0.0380 - val_loss: 7.0009 - val_pitch_output_loss: 4.8176 - val_rhythm_output_loss: 2.1833\n",
      "Epoch 56/2000\n",
      "3083/3083 [==============================] - 13s 4ms/step - loss: 0.1201 - pitch_output_loss: 0.0758 - rhythm_output_loss: 0.0443 - val_loss: 6.8338 - val_pitch_output_loss: 4.7314 - val_rhythm_output_loss: 2.1025\n",
      "Epoch 57/2000\n",
      "3083/3083 [==============================] - 13s 4ms/step - loss: 0.1112 - pitch_output_loss: 0.0728 - rhythm_output_loss: 0.0384 - val_loss: 6.8424 - val_pitch_output_loss: 4.6951 - val_rhythm_output_loss: 2.1473\n",
      "Epoch 58/2000\n",
      "3083/3083 [==============================] - 12s 4ms/step - loss: 0.1257 - pitch_output_loss: 0.0793 - rhythm_output_loss: 0.0465 - val_loss: 7.0097 - val_pitch_output_loss: 4.8824 - val_rhythm_output_loss: 2.1273\n",
      "Epoch 59/2000\n",
      "3083/3083 [==============================] - 13s 4ms/step - loss: 0.1141 - pitch_output_loss: 0.0768 - rhythm_output_loss: 0.0373 - val_loss: 7.0504 - val_pitch_output_loss: 4.8740 - val_rhythm_output_loss: 2.1764\n",
      "Epoch 60/2000\n",
      "3083/3083 [==============================] - 12s 4ms/step - loss: 0.1137 - pitch_output_loss: 0.0725 - rhythm_output_loss: 0.0413 - val_loss: 6.8941 - val_pitch_output_loss: 4.8257 - val_rhythm_output_loss: 2.0684\n",
      "Epoch 61/2000\n",
      "  75/3083 [..............................] - ETA: 12s - loss: 0.0477 - pitch_output_loss: 0.0470 - rhythm_output_loss: 6.5367e-04"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-461cc35adb4a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     26\u001b[0m           \u001b[1;33m,\u001b[0m \u001b[0mvalidation_split\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m           \u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallbacks_list\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m           \u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m          )\n",
      "\u001b[1;32m~\\.conda\\envs\\generative\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1040\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32m~\\.conda\\envs\\generative\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\generative\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\generative\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\generative\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[0;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1458\u001b[1;33m                                                run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1459\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "number_of_epochs = 2000\n",
    "size_of_batch = 15\n",
    "\n",
    "model_checkpoint = ModelCheckpoint(\n",
    "    os.path.join(model_folder, \"weights.h5\"),\n",
    "    monitor='loss',\n",
    "    verbose=0,\n",
    "    save_best_only=True,\n",
    "    mode='min'\n",
    ")\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='loss'\n",
    "    , restore_best_weights=True\n",
    "    , patience = 25\n",
    ")\n",
    "\n",
    "\n",
    "callbacks_list = [model_checkpoint, early_stopping]\n",
    "\n",
    "model.save_weights(os.path.join(model_folder, \"weights.h5\"))\n",
    "\n",
    "# Train the model\n",
    "model.fit(network_in, network_out\n",
    "          , epochs=number_of_epochs, batch_size=size_of_batch\n",
    "          , validation_split = 0.2\n",
    "          , callbacks=callbacks_list\n",
    "          , shuffle=True\n",
    "         )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(os.path.join(model_folder, \"my_model\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
